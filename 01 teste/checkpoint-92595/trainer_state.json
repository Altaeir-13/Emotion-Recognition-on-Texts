{
  "best_global_step": 92595,
  "best_metric": 0.3894813940268485,
  "best_model_checkpoint": "./resultados_final_gold\\checkpoint-92595",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 92595,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016199578810950917,
      "grad_norm": 1.6811071634292603,
      "learning_rate": 1.991916410173336e-05,
      "loss": 0.3637,
      "step": 500
    },
    {
      "epoch": 0.03239915762190183,
      "grad_norm": 1.4012812376022339,
      "learning_rate": 1.98381662076786e-05,
      "loss": 0.2866,
      "step": 1000
    },
    {
      "epoch": 0.04859873643285274,
      "grad_norm": 2.4166030883789062,
      "learning_rate": 1.9757168313623846e-05,
      "loss": 0.2721,
      "step": 1500
    },
    {
      "epoch": 0.06479831524380367,
      "grad_norm": 1.9425510168075562,
      "learning_rate": 1.9676170419569094e-05,
      "loss": 0.2664,
      "step": 2000
    },
    {
      "epoch": 0.08099789405475458,
      "grad_norm": 2.0534932613372803,
      "learning_rate": 1.9595334521302448e-05,
      "loss": 0.2588,
      "step": 2500
    },
    {
      "epoch": 0.09719747286570549,
      "grad_norm": 1.228622317314148,
      "learning_rate": 1.9514336627247693e-05,
      "loss": 0.2561,
      "step": 3000
    },
    {
      "epoch": 0.11339705167665641,
      "grad_norm": 2.5598719120025635,
      "learning_rate": 1.943333873319294e-05,
      "loss": 0.2504,
      "step": 3500
    },
    {
      "epoch": 0.12959663048760733,
      "grad_norm": 1.4439060688018799,
      "learning_rate": 1.9352340839138184e-05,
      "loss": 0.2484,
      "step": 4000
    },
    {
      "epoch": 0.14579620929855824,
      "grad_norm": 1.2398959398269653,
      "learning_rate": 1.927134294508343e-05,
      "loss": 0.2435,
      "step": 4500
    },
    {
      "epoch": 0.16199578810950915,
      "grad_norm": 1.8530923128128052,
      "learning_rate": 1.9190507046816783e-05,
      "loss": 0.2455,
      "step": 5000
    },
    {
      "epoch": 0.17819536692046006,
      "grad_norm": 1.3998584747314453,
      "learning_rate": 1.9109509152762028e-05,
      "loss": 0.2457,
      "step": 5500
    },
    {
      "epoch": 0.19439494573141097,
      "grad_norm": 1.5664935111999512,
      "learning_rate": 1.9028511258707277e-05,
      "loss": 0.2425,
      "step": 6000
    },
    {
      "epoch": 0.2105945245423619,
      "grad_norm": 2.1929752826690674,
      "learning_rate": 1.8947513364652522e-05,
      "loss": 0.2369,
      "step": 6500
    },
    {
      "epoch": 0.22679410335331282,
      "grad_norm": 1.313316822052002,
      "learning_rate": 1.8866515470597767e-05,
      "loss": 0.2344,
      "step": 7000
    },
    {
      "epoch": 0.24299368216426373,
      "grad_norm": 1.3174009323120117,
      "learning_rate": 1.878551757654301e-05,
      "loss": 0.2339,
      "step": 7500
    },
    {
      "epoch": 0.25919326097521467,
      "grad_norm": 1.3573397397994995,
      "learning_rate": 1.8704519682488255e-05,
      "loss": 0.2384,
      "step": 8000
    },
    {
      "epoch": 0.2753928397861656,
      "grad_norm": 1.2882652282714844,
      "learning_rate": 1.8623521788433503e-05,
      "loss": 0.2294,
      "step": 8500
    },
    {
      "epoch": 0.2915924185971165,
      "grad_norm": 1.90542733669281,
      "learning_rate": 1.8542685890166857e-05,
      "loss": 0.233,
      "step": 9000
    },
    {
      "epoch": 0.3077919974080674,
      "grad_norm": 2.9637765884399414,
      "learning_rate": 1.8461687996112102e-05,
      "loss": 0.227,
      "step": 9500
    },
    {
      "epoch": 0.3239915762190183,
      "grad_norm": 1.1645374298095703,
      "learning_rate": 1.8380690102057347e-05,
      "loss": 0.2281,
      "step": 10000
    },
    {
      "epoch": 0.3401911550299692,
      "grad_norm": 2.7869818210601807,
      "learning_rate": 1.8299692208002593e-05,
      "loss": 0.2274,
      "step": 10500
    },
    {
      "epoch": 0.3563907338409201,
      "grad_norm": 0.9302777647972107,
      "learning_rate": 1.8218694313947838e-05,
      "loss": 0.2284,
      "step": 11000
    },
    {
      "epoch": 0.37259031265187104,
      "grad_norm": 1.487111210823059,
      "learning_rate": 1.813785841568119e-05,
      "loss": 0.2242,
      "step": 11500
    },
    {
      "epoch": 0.38878989146282195,
      "grad_norm": 1.1146973371505737,
      "learning_rate": 1.8056860521626437e-05,
      "loss": 0.2251,
      "step": 12000
    },
    {
      "epoch": 0.40498947027377286,
      "grad_norm": 1.8444010019302368,
      "learning_rate": 1.7975862627571686e-05,
      "loss": 0.2227,
      "step": 12500
    },
    {
      "epoch": 0.4211890490847238,
      "grad_norm": 1.3552961349487305,
      "learning_rate": 1.789486473351693e-05,
      "loss": 0.2236,
      "step": 13000
    },
    {
      "epoch": 0.43738862789567473,
      "grad_norm": 2.308417797088623,
      "learning_rate": 1.7814028835250284e-05,
      "loss": 0.2211,
      "step": 13500
    },
    {
      "epoch": 0.45358820670662564,
      "grad_norm": 1.4549411535263062,
      "learning_rate": 1.773319293698364e-05,
      "loss": 0.2241,
      "step": 14000
    },
    {
      "epoch": 0.46978778551757655,
      "grad_norm": 1.3878253698349,
      "learning_rate": 1.7652195042928887e-05,
      "loss": 0.2189,
      "step": 14500
    },
    {
      "epoch": 0.48598736432852746,
      "grad_norm": 1.2691410779953003,
      "learning_rate": 1.7571197148874132e-05,
      "loss": 0.2186,
      "step": 15000
    },
    {
      "epoch": 0.5021869431394784,
      "grad_norm": 2.6340489387512207,
      "learning_rate": 1.7490199254819377e-05,
      "loss": 0.2112,
      "step": 15500
    },
    {
      "epoch": 0.5183865219504293,
      "grad_norm": 1.2674816846847534,
      "learning_rate": 1.7409201360764623e-05,
      "loss": 0.2173,
      "step": 16000
    },
    {
      "epoch": 0.5345861007613802,
      "grad_norm": 1.902162790298462,
      "learning_rate": 1.7328203466709868e-05,
      "loss": 0.2196,
      "step": 16500
    },
    {
      "epoch": 0.5507856795723312,
      "grad_norm": 2.683943748474121,
      "learning_rate": 1.7247205572655113e-05,
      "loss": 0.212,
      "step": 17000
    },
    {
      "epoch": 0.5669852583832821,
      "grad_norm": 1.6651573181152344,
      "learning_rate": 1.716620767860036e-05,
      "loss": 0.2095,
      "step": 17500
    },
    {
      "epoch": 0.583184837194233,
      "grad_norm": 1.5261423587799072,
      "learning_rate": 1.7085209784545604e-05,
      "loss": 0.2114,
      "step": 18000
    },
    {
      "epoch": 0.5993844160051839,
      "grad_norm": 2.1502084732055664,
      "learning_rate": 1.700421189049085e-05,
      "loss": 0.2096,
      "step": 18500
    },
    {
      "epoch": 0.6155839948161348,
      "grad_norm": 1.095648169517517,
      "learning_rate": 1.6923213996436094e-05,
      "loss": 0.2184,
      "step": 19000
    },
    {
      "epoch": 0.6317835736270857,
      "grad_norm": 2.9021801948547363,
      "learning_rate": 1.684221610238134e-05,
      "loss": 0.2091,
      "step": 19500
    },
    {
      "epoch": 0.6479831524380366,
      "grad_norm": 2.4263012409210205,
      "learning_rate": 1.6761218208326585e-05,
      "loss": 0.2073,
      "step": 20000
    },
    {
      "epoch": 0.6641827312489875,
      "grad_norm": 1.6113992929458618,
      "learning_rate": 1.668054430584805e-05,
      "loss": 0.2094,
      "step": 20500
    },
    {
      "epoch": 0.6803823100599384,
      "grad_norm": 3.036843776702881,
      "learning_rate": 1.6599546411793295e-05,
      "loss": 0.201,
      "step": 21000
    },
    {
      "epoch": 0.6965818888708893,
      "grad_norm": 2.341338872909546,
      "learning_rate": 1.651871051352665e-05,
      "loss": 0.2072,
      "step": 21500
    },
    {
      "epoch": 0.7127814676818403,
      "grad_norm": 1.9066511392593384,
      "learning_rate": 1.6437712619471894e-05,
      "loss": 0.2053,
      "step": 22000
    },
    {
      "epoch": 0.7289810464927912,
      "grad_norm": 1.881639838218689,
      "learning_rate": 1.635671472541714e-05,
      "loss": 0.2048,
      "step": 22500
    },
    {
      "epoch": 0.7451806253037421,
      "grad_norm": 1.6378722190856934,
      "learning_rate": 1.6275716831362388e-05,
      "loss": 0.2013,
      "step": 23000
    },
    {
      "epoch": 0.761380204114693,
      "grad_norm": 1.0864038467407227,
      "learning_rate": 1.619471893730763e-05,
      "loss": 0.206,
      "step": 23500
    },
    {
      "epoch": 0.7775797829256439,
      "grad_norm": 1.62398099899292,
      "learning_rate": 1.6113721043252876e-05,
      "loss": 0.2049,
      "step": 24000
    },
    {
      "epoch": 0.7937793617365948,
      "grad_norm": 2.126976490020752,
      "learning_rate": 1.603272314919812e-05,
      "loss": 0.2014,
      "step": 24500
    },
    {
      "epoch": 0.8099789405475457,
      "grad_norm": 3.609269380569458,
      "learning_rate": 1.5951725255143366e-05,
      "loss": 0.2002,
      "step": 25000
    },
    {
      "epoch": 0.8261785193584967,
      "grad_norm": 1.6274226903915405,
      "learning_rate": 1.5870889356876723e-05,
      "loss": 0.1987,
      "step": 25500
    },
    {
      "epoch": 0.8423780981694476,
      "grad_norm": 2.5159285068511963,
      "learning_rate": 1.578989146282197e-05,
      "loss": 0.2022,
      "step": 26000
    },
    {
      "epoch": 0.8585776769803986,
      "grad_norm": 0.9203016757965088,
      "learning_rate": 1.5708893568767214e-05,
      "loss": 0.1985,
      "step": 26500
    },
    {
      "epoch": 0.8747772557913495,
      "grad_norm": 2.3361761569976807,
      "learning_rate": 1.562789567471246e-05,
      "loss": 0.1965,
      "step": 27000
    },
    {
      "epoch": 0.8909768346023004,
      "grad_norm": 0.9619894027709961,
      "learning_rate": 1.5547059776445816e-05,
      "loss": 0.1974,
      "step": 27500
    },
    {
      "epoch": 0.9071764134132513,
      "grad_norm": 2.0525927543640137,
      "learning_rate": 1.5466061882391058e-05,
      "loss": 0.2027,
      "step": 28000
    },
    {
      "epoch": 0.9233759922242022,
      "grad_norm": 1.3252170085906982,
      "learning_rate": 1.5385063988336303e-05,
      "loss": 0.196,
      "step": 28500
    },
    {
      "epoch": 0.9395755710351531,
      "grad_norm": 1.7335014343261719,
      "learning_rate": 1.530406609428155e-05,
      "loss": 0.2,
      "step": 29000
    },
    {
      "epoch": 0.955775149846104,
      "grad_norm": 1.9305427074432373,
      "learning_rate": 1.5223068200226795e-05,
      "loss": 0.1961,
      "step": 29500
    },
    {
      "epoch": 0.9719747286570549,
      "grad_norm": 2.0651776790618896,
      "learning_rate": 1.514223230196015e-05,
      "loss": 0.196,
      "step": 30000
    },
    {
      "epoch": 0.9881743074680058,
      "grad_norm": 3.0101046562194824,
      "learning_rate": 1.5061234407905396e-05,
      "loss": 0.201,
      "step": 30500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.29,
      "eval_f1_macro": 0.33943529799863614,
      "eval_loss": 0.49583226442337036,
      "eval_runtime": 0.6274,
      "eval_samples_per_second": 637.548,
      "eval_steps_per_second": 39.847,
      "step": 30865
    },
    {
      "epoch": 1.0043738862789569,
      "grad_norm": 2.281503438949585,
      "learning_rate": 1.4980398509638751e-05,
      "loss": 0.1908,
      "step": 31000
    },
    {
      "epoch": 1.0205734650899076,
      "grad_norm": 2.033639430999756,
      "learning_rate": 1.4899400615583996e-05,
      "loss": 0.1722,
      "step": 31500
    },
    {
      "epoch": 1.0367730439008587,
      "grad_norm": 1.8704290390014648,
      "learning_rate": 1.4818402721529242e-05,
      "loss": 0.1808,
      "step": 32000
    },
    {
      "epoch": 1.0529726227118095,
      "grad_norm": 1.127615213394165,
      "learning_rate": 1.4737404827474487e-05,
      "loss": 0.1766,
      "step": 32500
    },
    {
      "epoch": 1.0691722015227605,
      "grad_norm": 1.4291439056396484,
      "learning_rate": 1.465640693341973e-05,
      "loss": 0.1754,
      "step": 33000
    },
    {
      "epoch": 1.0853717803337113,
      "grad_norm": 3.4618098735809326,
      "learning_rate": 1.4575409039364978e-05,
      "loss": 0.177,
      "step": 33500
    },
    {
      "epoch": 1.1015713591446623,
      "grad_norm": 2.956562042236328,
      "learning_rate": 1.4494411145310223e-05,
      "loss": 0.1745,
      "step": 34000
    },
    {
      "epoch": 1.117770937955613,
      "grad_norm": 1.2787506580352783,
      "learning_rate": 1.4413413251255468e-05,
      "loss": 0.1762,
      "step": 34500
    },
    {
      "epoch": 1.1339705167665641,
      "grad_norm": 2.5513782501220703,
      "learning_rate": 1.4332577352988824e-05,
      "loss": 0.1749,
      "step": 35000
    },
    {
      "epoch": 1.150170095577515,
      "grad_norm": 3.4618642330169678,
      "learning_rate": 1.4251579458934069e-05,
      "loss": 0.1769,
      "step": 35500
    },
    {
      "epoch": 1.166369674388466,
      "grad_norm": 2.5996925830841064,
      "learning_rate": 1.4170581564879312e-05,
      "loss": 0.1771,
      "step": 36000
    },
    {
      "epoch": 1.1825692531994167,
      "grad_norm": 1.919553518295288,
      "learning_rate": 1.4089583670824561e-05,
      "loss": 0.1752,
      "step": 36500
    },
    {
      "epoch": 1.1987688320103678,
      "grad_norm": 2.58866286277771,
      "learning_rate": 1.4008585776769805e-05,
      "loss": 0.1763,
      "step": 37000
    },
    {
      "epoch": 1.2149684108213186,
      "grad_norm": 3.336374044418335,
      "learning_rate": 1.392758788271505e-05,
      "loss": 0.1749,
      "step": 37500
    },
    {
      "epoch": 1.2311679896322696,
      "grad_norm": 2.2862977981567383,
      "learning_rate": 1.3846751984448405e-05,
      "loss": 0.1783,
      "step": 38000
    },
    {
      "epoch": 1.2473675684432204,
      "grad_norm": 1.754939079284668,
      "learning_rate": 1.376575409039365e-05,
      "loss": 0.1753,
      "step": 38500
    },
    {
      "epoch": 1.2635671472541714,
      "grad_norm": 1.8510359525680542,
      "learning_rate": 1.3684756196338896e-05,
      "loss": 0.1758,
      "step": 39000
    },
    {
      "epoch": 1.2797667260651222,
      "grad_norm": 2.3435981273651123,
      "learning_rate": 1.3603758302284143e-05,
      "loss": 0.1677,
      "step": 39500
    },
    {
      "epoch": 1.2959663048760732,
      "grad_norm": 2.128190279006958,
      "learning_rate": 1.3522922404017495e-05,
      "loss": 0.179,
      "step": 40000
    },
    {
      "epoch": 1.3121658836870242,
      "grad_norm": 3.1595661640167236,
      "learning_rate": 1.3441924509962743e-05,
      "loss": 0.179,
      "step": 40500
    },
    {
      "epoch": 1.328365462497975,
      "grad_norm": 1.991690993309021,
      "learning_rate": 1.3360926615907987e-05,
      "loss": 0.1696,
      "step": 41000
    },
    {
      "epoch": 1.3445650413089258,
      "grad_norm": 2.155336856842041,
      "learning_rate": 1.3280090717641342e-05,
      "loss": 0.1724,
      "step": 41500
    },
    {
      "epoch": 1.3607646201198769,
      "grad_norm": 1.9365642070770264,
      "learning_rate": 1.3199092823586588e-05,
      "loss": 0.1757,
      "step": 42000
    },
    {
      "epoch": 1.3769641989308279,
      "grad_norm": 3.4363512992858887,
      "learning_rate": 1.3118094929531833e-05,
      "loss": 0.1745,
      "step": 42500
    },
    {
      "epoch": 1.3931637777417787,
      "grad_norm": 2.186138153076172,
      "learning_rate": 1.3037097035477078e-05,
      "loss": 0.1698,
      "step": 43000
    },
    {
      "epoch": 1.4093633565527297,
      "grad_norm": 1.7386952638626099,
      "learning_rate": 1.2956099141422325e-05,
      "loss": 0.1744,
      "step": 43500
    },
    {
      "epoch": 1.4255629353636805,
      "grad_norm": 2.42362380027771,
      "learning_rate": 1.2875101247367569e-05,
      "loss": 0.1697,
      "step": 44000
    },
    {
      "epoch": 1.4417625141746315,
      "grad_norm": 2.3535797595977783,
      "learning_rate": 1.2794103353312814e-05,
      "loss": 0.1731,
      "step": 44500
    },
    {
      "epoch": 1.4579620929855823,
      "grad_norm": 2.1068851947784424,
      "learning_rate": 1.271310545925806e-05,
      "loss": 0.1725,
      "step": 45000
    },
    {
      "epoch": 1.4741616717965333,
      "grad_norm": 1.4866175651550293,
      "learning_rate": 1.2632107565203306e-05,
      "loss": 0.1719,
      "step": 45500
    },
    {
      "epoch": 1.4903612506074841,
      "grad_norm": 2.564277410507202,
      "learning_rate": 1.2551109671148552e-05,
      "loss": 0.1741,
      "step": 46000
    },
    {
      "epoch": 1.5065608294184352,
      "grad_norm": 2.504030466079712,
      "learning_rate": 1.2470273772881907e-05,
      "loss": 0.1694,
      "step": 46500
    },
    {
      "epoch": 1.5227604082293862,
      "grad_norm": 1.845929503440857,
      "learning_rate": 1.2389275878827152e-05,
      "loss": 0.1714,
      "step": 47000
    },
    {
      "epoch": 1.538959987040337,
      "grad_norm": 2.8110735416412354,
      "learning_rate": 1.2308277984772396e-05,
      "loss": 0.1717,
      "step": 47500
    },
    {
      "epoch": 1.5551595658512878,
      "grad_norm": 2.6179115772247314,
      "learning_rate": 1.2227280090717641e-05,
      "loss": 0.172,
      "step": 48000
    },
    {
      "epoch": 1.5713591446622388,
      "grad_norm": 1.6630598306655884,
      "learning_rate": 1.2146282196662888e-05,
      "loss": 0.1718,
      "step": 48500
    },
    {
      "epoch": 1.5875587234731898,
      "grad_norm": 1.4434374570846558,
      "learning_rate": 1.2065446298396242e-05,
      "loss": 0.1725,
      "step": 49000
    },
    {
      "epoch": 1.6037583022841406,
      "grad_norm": 1.5819871425628662,
      "learning_rate": 1.1984448404341489e-05,
      "loss": 0.1719,
      "step": 49500
    },
    {
      "epoch": 1.6199578810950914,
      "grad_norm": 5.193835258483887,
      "learning_rate": 1.1903450510286734e-05,
      "loss": 0.1723,
      "step": 50000
    },
    {
      "epoch": 1.6361574599060424,
      "grad_norm": 2.36222243309021,
      "learning_rate": 1.182245261623198e-05,
      "loss": 0.1675,
      "step": 50500
    },
    {
      "epoch": 1.6523570387169935,
      "grad_norm": 1.8857934474945068,
      "learning_rate": 1.1741616717965335e-05,
      "loss": 0.1717,
      "step": 51000
    },
    {
      "epoch": 1.6685566175279443,
      "grad_norm": 1.3728702068328857,
      "learning_rate": 1.166078081969869e-05,
      "loss": 0.1686,
      "step": 51500
    },
    {
      "epoch": 1.684756196338895,
      "grad_norm": 2.946057081222534,
      "learning_rate": 1.1579782925643935e-05,
      "loss": 0.1695,
      "step": 52000
    },
    {
      "epoch": 1.700955775149846,
      "grad_norm": 3.183645486831665,
      "learning_rate": 1.1498785031589179e-05,
      "loss": 0.172,
      "step": 52500
    },
    {
      "epoch": 1.717155353960797,
      "grad_norm": 1.7868449687957764,
      "learning_rate": 1.1417949133322534e-05,
      "loss": 0.1684,
      "step": 53000
    },
    {
      "epoch": 1.733354932771748,
      "grad_norm": 3.1512250900268555,
      "learning_rate": 1.133695123926778e-05,
      "loss": 0.1705,
      "step": 53500
    },
    {
      "epoch": 1.7495545115826987,
      "grad_norm": 3.4037134647369385,
      "learning_rate": 1.1255953345213024e-05,
      "loss": 0.166,
      "step": 54000
    },
    {
      "epoch": 1.7657540903936497,
      "grad_norm": 2.7574989795684814,
      "learning_rate": 1.1174955451158272e-05,
      "loss": 0.1658,
      "step": 54500
    },
    {
      "epoch": 1.7819536692046007,
      "grad_norm": 2.514735460281372,
      "learning_rate": 1.1093957557103517e-05,
      "loss": 0.165,
      "step": 55000
    },
    {
      "epoch": 1.7981532480155515,
      "grad_norm": 2.0786640644073486,
      "learning_rate": 1.101295966304876e-05,
      "loss": 0.1687,
      "step": 55500
    },
    {
      "epoch": 1.8143528268265026,
      "grad_norm": 1.824839472770691,
      "learning_rate": 1.0931961768994006e-05,
      "loss": 0.1652,
      "step": 56000
    },
    {
      "epoch": 1.8305524056374534,
      "grad_norm": 2.433074712753296,
      "learning_rate": 1.0850963874939253e-05,
      "loss": 0.1684,
      "step": 56500
    },
    {
      "epoch": 1.8467519844484044,
      "grad_norm": 3.0021731853485107,
      "learning_rate": 1.0770127976672606e-05,
      "loss": 0.1669,
      "step": 57000
    },
    {
      "epoch": 1.8629515632593554,
      "grad_norm": 2.755984306335449,
      "learning_rate": 1.0689130082617853e-05,
      "loss": 0.1619,
      "step": 57500
    },
    {
      "epoch": 1.8791511420703062,
      "grad_norm": 2.9269776344299316,
      "learning_rate": 1.0608132188563099e-05,
      "loss": 0.1668,
      "step": 58000
    },
    {
      "epoch": 1.895350720881257,
      "grad_norm": 3.321308135986328,
      "learning_rate": 1.0527134294508344e-05,
      "loss": 0.1651,
      "step": 58500
    },
    {
      "epoch": 1.911550299692208,
      "grad_norm": 1.5034615993499756,
      "learning_rate": 1.0446136400453588e-05,
      "loss": 0.1664,
      "step": 59000
    },
    {
      "epoch": 1.927749878503159,
      "grad_norm": 2.2401466369628906,
      "learning_rate": 1.0365138506398835e-05,
      "loss": 0.1613,
      "step": 59500
    },
    {
      "epoch": 1.9439494573141098,
      "grad_norm": 1.4039119482040405,
      "learning_rate": 1.0284302608132188e-05,
      "loss": 0.1664,
      "step": 60000
    },
    {
      "epoch": 1.9601490361250606,
      "grad_norm": 2.295490264892578,
      "learning_rate": 1.0203304714077435e-05,
      "loss": 0.1621,
      "step": 60500
    },
    {
      "epoch": 1.9763486149360117,
      "grad_norm": 2.56099534034729,
      "learning_rate": 1.012230682002268e-05,
      "loss": 0.1659,
      "step": 61000
    },
    {
      "epoch": 1.9925481937469627,
      "grad_norm": 2.2062904834747314,
      "learning_rate": 1.0041308925967926e-05,
      "loss": 0.1673,
      "step": 61500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.32,
      "eval_f1_macro": 0.35709092098709144,
      "eval_loss": 0.4699628949165344,
      "eval_runtime": 0.6817,
      "eval_samples_per_second": 586.806,
      "eval_steps_per_second": 36.675,
      "step": 61730
    },
    {
      "epoch": 2.0087477725579137,
      "grad_norm": 4.115717887878418,
      "learning_rate": 9.960311031913171e-06,
      "loss": 0.1543,
      "step": 62000
    },
    {
      "epoch": 2.0249473513688643,
      "grad_norm": 4.051231384277344,
      "learning_rate": 9.879313137858416e-06,
      "loss": 0.1429,
      "step": 62500
    },
    {
      "epoch": 2.0411469301798153,
      "grad_norm": 2.211235523223877,
      "learning_rate": 9.798315243803662e-06,
      "loss": 0.1448,
      "step": 63000
    },
    {
      "epoch": 2.0573465089907663,
      "grad_norm": 5.870870113372803,
      "learning_rate": 9.717317349748907e-06,
      "loss": 0.1423,
      "step": 63500
    },
    {
      "epoch": 2.0735460878017173,
      "grad_norm": 1.085595726966858,
      "learning_rate": 9.636481451482262e-06,
      "loss": 0.1454,
      "step": 64000
    },
    {
      "epoch": 2.089745666612668,
      "grad_norm": 1.017288327217102,
      "learning_rate": 9.555483557427507e-06,
      "loss": 0.1419,
      "step": 64500
    },
    {
      "epoch": 2.105945245423619,
      "grad_norm": 5.008656024932861,
      "learning_rate": 9.474647659160863e-06,
      "loss": 0.1453,
      "step": 65000
    },
    {
      "epoch": 2.12214482423457,
      "grad_norm": 4.00335168838501,
      "learning_rate": 9.393649765106108e-06,
      "loss": 0.1511,
      "step": 65500
    },
    {
      "epoch": 2.138344403045521,
      "grad_norm": 2.939640998840332,
      "learning_rate": 9.312651871051353e-06,
      "loss": 0.1502,
      "step": 66000
    },
    {
      "epoch": 2.1545439818564716,
      "grad_norm": 1.742028832435608,
      "learning_rate": 9.231653976996599e-06,
      "loss": 0.1444,
      "step": 66500
    },
    {
      "epoch": 2.1707435606674226,
      "grad_norm": 1.9044890403747559,
      "learning_rate": 9.150656082941844e-06,
      "loss": 0.1485,
      "step": 67000
    },
    {
      "epoch": 2.1869431394783736,
      "grad_norm": 3.8323001861572266,
      "learning_rate": 9.06965818888709e-06,
      "loss": 0.1451,
      "step": 67500
    },
    {
      "epoch": 2.2031427182893246,
      "grad_norm": 1.4668906927108765,
      "learning_rate": 8.988660294832335e-06,
      "loss": 0.1508,
      "step": 68000
    },
    {
      "epoch": 2.219342297100275,
      "grad_norm": 3.552079200744629,
      "learning_rate": 8.90766240077758e-06,
      "loss": 0.1483,
      "step": 68500
    },
    {
      "epoch": 2.235541875911226,
      "grad_norm": 1.570920705795288,
      "learning_rate": 8.826664506722827e-06,
      "loss": 0.1462,
      "step": 69000
    },
    {
      "epoch": 2.2517414547221772,
      "grad_norm": 4.589962005615234,
      "learning_rate": 8.74582860845618e-06,
      "loss": 0.1519,
      "step": 69500
    },
    {
      "epoch": 2.2679410335331283,
      "grad_norm": 2.0986530780792236,
      "learning_rate": 8.664830714401426e-06,
      "loss": 0.1503,
      "step": 70000
    },
    {
      "epoch": 2.2841406123440793,
      "grad_norm": 1.1313002109527588,
      "learning_rate": 8.583832820346671e-06,
      "loss": 0.1493,
      "step": 70500
    },
    {
      "epoch": 2.30034019115503,
      "grad_norm": 1.951282024383545,
      "learning_rate": 8.502834926291918e-06,
      "loss": 0.1459,
      "step": 71000
    },
    {
      "epoch": 2.316539769965981,
      "grad_norm": 4.118443489074707,
      "learning_rate": 8.421837032237162e-06,
      "loss": 0.1453,
      "step": 71500
    },
    {
      "epoch": 2.332739348776932,
      "grad_norm": 2.472367286682129,
      "learning_rate": 8.341001133970519e-06,
      "loss": 0.1504,
      "step": 72000
    },
    {
      "epoch": 2.3489389275878825,
      "grad_norm": 2.705932140350342,
      "learning_rate": 8.260003239915762e-06,
      "loss": 0.1496,
      "step": 72500
    },
    {
      "epoch": 2.3651385063988335,
      "grad_norm": 5.008115291595459,
      "learning_rate": 8.17900534586101e-06,
      "loss": 0.143,
      "step": 73000
    },
    {
      "epoch": 2.3813380852097845,
      "grad_norm": 3.0180459022521973,
      "learning_rate": 8.098007451806253e-06,
      "loss": 0.1481,
      "step": 73500
    },
    {
      "epoch": 2.3975376640207355,
      "grad_norm": 1.2705154418945312,
      "learning_rate": 8.0170095577515e-06,
      "loss": 0.1474,
      "step": 74000
    },
    {
      "epoch": 2.4137372428316866,
      "grad_norm": 1.9932550191879272,
      "learning_rate": 7.936011663696745e-06,
      "loss": 0.1528,
      "step": 74500
    },
    {
      "epoch": 2.429936821642637,
      "grad_norm": 3.0021419525146484,
      "learning_rate": 7.8551757654301e-06,
      "loss": 0.1467,
      "step": 75000
    },
    {
      "epoch": 2.446136400453588,
      "grad_norm": 2.1999309062957764,
      "learning_rate": 7.774177871375344e-06,
      "loss": 0.1485,
      "step": 75500
    },
    {
      "epoch": 2.462335979264539,
      "grad_norm": 3.936082124710083,
      "learning_rate": 7.693179977320591e-06,
      "loss": 0.1478,
      "step": 76000
    },
    {
      "epoch": 2.47853555807549,
      "grad_norm": 1.4529166221618652,
      "learning_rate": 7.612182083265835e-06,
      "loss": 0.1464,
      "step": 76500
    },
    {
      "epoch": 2.4947351368864408,
      "grad_norm": 1.8210232257843018,
      "learning_rate": 7.531346184999191e-06,
      "loss": 0.1508,
      "step": 77000
    },
    {
      "epoch": 2.510934715697392,
      "grad_norm": 2.421313524246216,
      "learning_rate": 7.450348290944436e-06,
      "loss": 0.1492,
      "step": 77500
    },
    {
      "epoch": 2.527134294508343,
      "grad_norm": 1.82021164894104,
      "learning_rate": 7.369350396889682e-06,
      "loss": 0.1497,
      "step": 78000
    },
    {
      "epoch": 2.543333873319294,
      "grad_norm": 1.4978692531585693,
      "learning_rate": 7.2883525028349266e-06,
      "loss": 0.1475,
      "step": 78500
    },
    {
      "epoch": 2.5595334521302444,
      "grad_norm": 1.9357502460479736,
      "learning_rate": 7.207354608780173e-06,
      "loss": 0.1487,
      "step": 79000
    },
    {
      "epoch": 2.5757330309411954,
      "grad_norm": 1.0169978141784668,
      "learning_rate": 7.126356714725417e-06,
      "loss": 0.1478,
      "step": 79500
    },
    {
      "epoch": 2.5919326097521465,
      "grad_norm": 3.6967597007751465,
      "learning_rate": 7.045358820670663e-06,
      "loss": 0.1459,
      "step": 80000
    },
    {
      "epoch": 2.6081321885630975,
      "grad_norm": 2.0545451641082764,
      "learning_rate": 6.964522922404018e-06,
      "loss": 0.1484,
      "step": 80500
    },
    {
      "epoch": 2.6243317673740485,
      "grad_norm": 5.412919044494629,
      "learning_rate": 6.883525028349264e-06,
      "loss": 0.1525,
      "step": 81000
    },
    {
      "epoch": 2.640531346184999,
      "grad_norm": 2.804023265838623,
      "learning_rate": 6.802527134294508e-06,
      "loss": 0.1465,
      "step": 81500
    },
    {
      "epoch": 2.65673092499595,
      "grad_norm": 2.7111666202545166,
      "learning_rate": 6.7215292402397545e-06,
      "loss": 0.147,
      "step": 82000
    },
    {
      "epoch": 2.672930503806901,
      "grad_norm": 11.121657371520996,
      "learning_rate": 6.640531346185e-06,
      "loss": 0.1488,
      "step": 82500
    },
    {
      "epoch": 2.6891300826178517,
      "grad_norm": 1.5587800741195679,
      "learning_rate": 6.559533452130246e-06,
      "loss": 0.1472,
      "step": 83000
    },
    {
      "epoch": 2.7053296614288027,
      "grad_norm": 2.335320234298706,
      "learning_rate": 6.4785355580754905e-06,
      "loss": 0.1493,
      "step": 83500
    },
    {
      "epoch": 2.7215292402397537,
      "grad_norm": 1.2570338249206543,
      "learning_rate": 6.397537664020737e-06,
      "loss": 0.1462,
      "step": 84000
    },
    {
      "epoch": 2.7377288190507048,
      "grad_norm": 4.368431091308594,
      "learning_rate": 6.316539769965981e-06,
      "loss": 0.147,
      "step": 84500
    },
    {
      "epoch": 2.7539283978616558,
      "grad_norm": 3.8272430896759033,
      "learning_rate": 6.235703871699337e-06,
      "loss": 0.15,
      "step": 85000
    },
    {
      "epoch": 2.7701279766726064,
      "grad_norm": 3.075016498565674,
      "learning_rate": 6.154705977644582e-06,
      "loss": 0.1502,
      "step": 85500
    },
    {
      "epoch": 2.7863275554835574,
      "grad_norm": 2.65915584564209,
      "learning_rate": 6.073708083589828e-06,
      "loss": 0.145,
      "step": 86000
    },
    {
      "epoch": 2.8025271342945084,
      "grad_norm": 2.721900701522827,
      "learning_rate": 5.992710189535072e-06,
      "loss": 0.1438,
      "step": 86500
    },
    {
      "epoch": 2.8187267131054594,
      "grad_norm": 3.2233874797821045,
      "learning_rate": 5.911874291268428e-06,
      "loss": 0.1445,
      "step": 87000
    },
    {
      "epoch": 2.8349262919164104,
      "grad_norm": 2.2447762489318848,
      "learning_rate": 5.830876397213673e-06,
      "loss": 0.1453,
      "step": 87500
    },
    {
      "epoch": 2.851125870727361,
      "grad_norm": 3.178274154663086,
      "learning_rate": 5.750040498947028e-06,
      "loss": 0.1505,
      "step": 88000
    },
    {
      "epoch": 2.867325449538312,
      "grad_norm": 1.9085458517074585,
      "learning_rate": 5.669042604892273e-06,
      "loss": 0.1463,
      "step": 88500
    },
    {
      "epoch": 2.883525028349263,
      "grad_norm": 2.084777355194092,
      "learning_rate": 5.588044710837519e-06,
      "loss": 0.1497,
      "step": 89000
    },
    {
      "epoch": 2.8997246071602136,
      "grad_norm": 1.0903863906860352,
      "learning_rate": 5.507046816782764e-06,
      "loss": 0.1465,
      "step": 89500
    },
    {
      "epoch": 2.9159241859711647,
      "grad_norm": 2.190739870071411,
      "learning_rate": 5.42604892272801e-06,
      "loss": 0.143,
      "step": 90000
    },
    {
      "epoch": 2.9321237647821157,
      "grad_norm": 3.5407605171203613,
      "learning_rate": 5.3450510286732545e-06,
      "loss": 0.1423,
      "step": 90500
    },
    {
      "epoch": 2.9483233435930667,
      "grad_norm": 3.093040943145752,
      "learning_rate": 5.264053134618501e-06,
      "loss": 0.1519,
      "step": 91000
    },
    {
      "epoch": 2.9645229224040177,
      "grad_norm": 2.2904341220855713,
      "learning_rate": 5.183217236351855e-06,
      "loss": 0.1429,
      "step": 91500
    },
    {
      "epoch": 2.9807225012149683,
      "grad_norm": 2.401728868484497,
      "learning_rate": 5.102219342297101e-06,
      "loss": 0.1459,
      "step": 92000
    },
    {
      "epoch": 2.9969220800259193,
      "grad_norm": 2.743940591812134,
      "learning_rate": 5.021221448242346e-06,
      "loss": 0.1456,
      "step": 92500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.375,
      "eval_f1_macro": 0.3894813940268485,
      "eval_loss": 0.49113380908966064,
      "eval_runtime": 0.63,
      "eval_samples_per_second": 634.913,
      "eval_steps_per_second": 39.682,
      "step": 92595
    }
  ],
  "logging_steps": 500,
  "max_steps": 123460,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.745378321816166e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
